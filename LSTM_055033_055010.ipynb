{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting Stock Prices using LSTM\n",
        "\n",
        "###Priyadarshani Dash 055033 | Divyank Harjani 055010"
      ],
      "metadata": {
        "id": "0m_UyofKUphG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OBJECTIVE"
      ],
      "metadata": {
        "id": "ytlWbSK9Umvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to develop a Long Short-Term Memory (LSTM) based deep learning model to predict the stock prices of NIFTY 50 and HCL Tech using historical daily stock market data. The model aims to analyze stock price movements and assess the correlation between the Nifty50 stock index and HCL Tech stock performance."
      ],
      "metadata": {
        "id": "9ctJ134ZVTEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM STATEMENT"
      ],
      "metadata": {
        "id": "Q1xCB4ccUqfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary challenge of this project is predicting stock prices using time series data, which requires capturing complex patterns and trends. Additionally, the project examines how fluctuations in the Nifty 50 index impact the stock price of HCL Tech.\n",
        "\n",
        "Can we accurately predict future stock prices using historical data?\n",
        "\n",
        "What is the degree of correlation between NIFTY 50 and HCL Tech stock movements?\n",
        "\n",
        "How effectively does the LSTM model capture stock market trends compared to actual market fluctuations?"
      ],
      "metadata": {
        "id": "wvG7OtJVVbQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Preparation"
      ],
      "metadata": {
        "id": "l1wHv0ZaW29S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Source: Yahoo Finance (using the yfinance package) was used to fetch historical stock price data for:\n",
        "\n",
        "Nifty 50 Index: Ticker ^NSEI (National Stock Exchange Index)\n",
        "\n",
        "Reliance Industries: Ticker RELIANCE.NS\n",
        "\n",
        "Date Range: Data is taken from the last 730 days, with a 1-hour interval.\n",
        "\n",
        "Data Operations:\n",
        "\n",
        "Only the closing prices were extracted, as they provide a reliable summary of the stock’s performance on a given day.\n",
        "\n",
        "This data was stored in a Pandas DataFrame and normalized using MinMaxScaler to scale values between 0 and 1, improving model efficiency during training.\n",
        "\n",
        "The dataset was then split for training and testing.\n",
        "\n",
        "This was done for both Nifty50 and HCL Tech datasets.\n",
        "\n",
        "Although the model was trained only on the Nifty50 Index data, the HCL Tech stock data was also split to avoid errors."
      ],
      "metadata": {
        "id": "1HBzfdILWZmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notes and Observations"
      ],
      "metadata": {
        "id": "UxdmRubHPQWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We trained and validated both models on the Nifty50 data and then applied the same models to the HCL Tech dataset to predict stock prices.\n",
        "\n",
        "Instead of using pre-existing accuracy metrics, we developed our own metric: Mean Absolute Percentage Error (MAPE).\n",
        "\n",
        "Using this metric, the accuracy during training for the first model is 95.76%, while for the tuned model, it is 97.59%.\n",
        "\n",
        "Each epoch took approximately 20 seconds on average to run.\n",
        "\n",
        "When tested with HCL Tech stock prices, the first model achieved an accuracy of 97.94%, while the second (tuned) model showed an accuracy of 97.59%.\n",
        "\n",
        "We also calculated the correlation between the Nifty50 Stock Index and HCL Tech stock prices:\n",
        "\n",
        "The correlation on actual data is 0.56.\n",
        "\n",
        "The correlation on predicted data is 0.79.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yYJQ5tN9PS93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inferences"
      ],
      "metadata": {
        "id": "iYXcc_kKURor"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQ3xpSW78wTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Generalization Across Stocks:\n",
        "\n",
        "Both models were trained on Nifty50 data and showed strong performance when applied to HCL Tech stock prices, indicating that LSTM can effectively capture generalized market trends. The slight difference in accuracy between training and testing suggests that the model may have overfitted to the Nifty50 dataset to some extent.\n",
        "\n",
        "Impact of Hyperparameter Tuning:\n",
        "\n",
        "The first model (baseline) achieved a training accuracy of 95.76%, while the tuned model achieved 97.59%. This slight decrease in accuracy suggests that hyperparameter tuning, such as increased dropout, introduced more regularization, preventing overfitting.\n",
        "\n",
        "Despite the accuracy difference, the performance of the tuned model on HCL Tech remains similar (97.59% vs. 97.94%), indicating that further tuning may not lead to significant improvements for this dataset.\n",
        "\n",
        "Execution Time vs. Model Complexity:\n",
        "\n",
        "Each epoch takes around 20 seconds, which is reasonable for model training. However, for real-time stock prediction, optimizations such as reducing the LSTM layers or tuning the batch size may be necessary to improve execution time.\n",
        "\n",
        "Correlation Insights:\n",
        "\n",
        "The correlation between actual stock prices (0.56) suggests a moderate relationship between Nifty50 and HCL Tech stock prices.\n",
        "\n",
        "The correlation between predicted stock prices (0.79) shows that the model enhances this relationship, likely due to dependencies learned from the Nifty50 dataset.\n",
        "\n",
        "This suggests that LSTMs may be biased toward capturing broad market movements, which can be useful but could also pose a risk for making stock-specific predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "ql60oIrkUTpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Managerial Insights"
      ],
      "metadata": {
        "id": "eHQC1D-3RqcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The high accuracy of 97.59%-97.94% on HCL Tech stock shows that deep learning models can be valuable for investment strategies and risk assessment.\n",
        "\n",
        "2. Investors and portfolio managers can use these predictions to identify trends and optimize buy/sell decisions.\n",
        "\n",
        "3. Traders should not rely solely on index movements but also analyze company-specific factors (earnings, management decisions, sector performance).\n",
        "\n",
        "4.  For companies like HCL Tech, industry-specific variables (e.g., staffing demand, economic cycles, hiring trends) should be included in the dataset."
      ],
      "metadata": {
        "id": "by7QOXwlSM9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANALYSIS"
      ],
      "metadata": {
        "id": "nJcGYU6_UgVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nifty50"
      ],
      "metadata": {
        "id": "noYhbmlwU2nh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrIRT9HiP0ML",
        "outputId": "ec328b4e-bf68-4046-d551-118c548af30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement mape (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mape\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install yfinance tensorflow mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "muJy4qm8P0Mj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXkrVUXwP0Mk",
        "outputId": "25b130b4-5c38-4635-98bf-659c1696a5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# Download NIFTY 50 data (last 20 years)\n",
        "nifty_data = yf.download('^NSEI', period = '730d', interval = '1h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UI6m3k4fP0Mk"
      },
      "outputs": [],
      "source": [
        "# Extract closing prices\n",
        "data = nifty_data[['Close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Bsjh6oadP0M4"
      },
      "outputs": [],
      "source": [
        "# Normalize data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Gx8Q-aqYP0M4",
        "outputId": "eba7d48c-1b90-4480-bdcd-daaec87a649e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Price                             Close\n",
              "Ticker                            ^NSEI\n",
              "Datetime                               \n",
              "2022-04-19 03:45:00+00:00  17194.099609\n",
              "2022-04-19 04:45:00+00:00  17194.000000\n",
              "2022-04-19 05:45:00+00:00  17238.199219\n",
              "2022-04-19 06:45:00+00:00  17181.500000\n",
              "2022-04-19 07:45:00+00:00  17245.400391"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65f8ce9f-d20e-4503-b60a-ed457c2bfda3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th>^NSEI</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-04-19 03:45:00+00:00</th>\n",
              "      <td>17194.099609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-19 04:45:00+00:00</th>\n",
              "      <td>17194.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-19 05:45:00+00:00</th>\n",
              "      <td>17238.199219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-19 06:45:00+00:00</th>\n",
              "      <td>17181.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-19 07:45:00+00:00</th>\n",
              "      <td>17245.400391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65f8ce9f-d20e-4503-b60a-ed457c2bfda3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65f8ce9f-d20e-4503-b60a-ed457c2bfda3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65f8ce9f-d20e-4503-b60a-ed457c2bfda3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13f3c5b7-d08b-43c6-849b-96ba09846bca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13f3c5b7-d08b-43c6-849b-96ba09846bca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13f3c5b7-d08b-43c6-849b-96ba09846bca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5097,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Datetime\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-04-19 03:45:00+00:00\",\n        \"max\": \"2025-03-28 09:45:00+00:00\",\n        \"num_unique_values\": 5097,\n        \"samples\": [\n          \"2022-11-15 04:45:00+00:00\",\n          \"2023-01-12 09:45:00+00:00\",\n          \"2022-10-12 04:45:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Close\",\n        \"^NSEI\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2873.684471642652,\n        \"min\": 15265.2998046875,\n        \"max\": 26262.25,\n        \"num_unique_values\": 5007,\n        \"samples\": [\n          24810.599609375,\n          19350.400390625,\n          24629.150390625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "#show data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "pv0YUIQSP0M4"
      },
      "outputs": [],
      "source": [
        "# Prepare training data\n",
        "def create_sequences(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OCNh6jA8P0M5"
      },
      "outputs": [],
      "source": [
        "time_step = 60  # Using past 60 days for prediction\n",
        "X, y = create_sequences(data_scaled, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "a_rF5CeTP0M5"
      },
      "outputs": [],
      "source": [
        "# Split into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nwJ7saH5P0NQ"
      },
      "outputs": [],
      "source": [
        "# Reshape for LSTM input\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "68iHyyq6P0NQ",
        "outputId": "2112f18d-3bd0-449f-af96-c7b63d34d6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m10,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)                  │           \u001b[38;5;34m1,275\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m26\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,275</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,101\u001b[0m (203.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,101</span> (203.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,101\u001b[0m (203.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,101</span> (203.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=25, activation='relu'),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Q2uzYbvEP0NR"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "oWpja7d3P0NR"
      },
      "outputs": [],
      "source": [
        "# Define accuracy metric (Mean Absolute Percentage Error - MAPE)\n",
        "def mape(y_true, y_pred_nifty):\n",
        "    y_true, y_pred_nifty = np.array(y_true), np.array(y_pred_nifty)\n",
        "    nonzero_idx = y_true != 0  # Avoid division by zero\n",
        "    return np.mean(np.abs((y_true[nonzero_idx] - y_pred_nifty[nonzero_idx]) / y_true[nonzero_idx])) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "vEAdAjzgP0Ni"
      },
      "outputs": [],
      "source": [
        "# Custom callback to print loss and accuracy after each epoch\n",
        "class EpochCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch+1}: Loss = {logs['loss']:.4f}, Val Loss = {logs['val_loss']:.4f}, MAE = {logs['mae']:.4f}, Val MAE = {logs['val_mae']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsGJRTHP0Ni",
        "outputId": "5595184c-dafa-43f5-a206-cb0fbb0b4609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0401 - mae: 0.1245Epoch 1: Loss = 0.0129, Val Loss = 0.0017, MAE = 0.0633, Val MAE = 0.0364\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.0399 - mae: 0.1240 - val_loss: 0.0017 - val_mae: 0.0364\n",
            "Epoch 2/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0019 - mae: 0.0307Epoch 2: Loss = 0.0018, Val Loss = 0.0006, MAE = 0.0297, Val MAE = 0.0199\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 5.8361e-04 - val_mae: 0.0199\n",
            "Epoch 3/10\n"
          ]
        }
      ],
      "source": [
        "# Train the model and store training history\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[EpochCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('LSTMNifty.keras')"
      ],
      "metadata": {
        "id": "FEx4-0uQ5NNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0O5c3VYP0Nj"
      },
      "outputs": [],
      "source": [
        "# Predict on test data\n",
        "y_pred_nifty = model.predict(X_test)\n",
        "y_pred_nifty = scaler.inverse_transform(y_pred_nifty.reshape(-1, 1))\n",
        "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX--zcsvP0Nj"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy using MAPE\n",
        "accuracy = 100 - mape(y_test_actual, y_pred_nifty)\n",
        "print(f\"Final Model Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sevCYLv3P0Nj"
      },
      "outputs": [],
      "source": [
        "# Plot results year-wise\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(nifty_data.index[split+time_step+1:], y_test_actual, label='Actual Price')\n",
        "plt.plot(nifty_data.index[split+time_step+1:], y_pred_nifty, label='Predicted Price')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('NIFTY 50 Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.title('NIFTY 50 Price Prediction using LSTM (Year-wise)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oclDbkFFP0Nk"
      },
      "source": [
        "##QuessCorp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "\n",
        "# Download HCL Tech stock data (last 2 years)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Extract closing prices\n",
        "data = hcl_data[['Close']]\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data[['Close']])\n",
        "\n",
        "# Prepare sequences using the past 60 hours for prediction\n",
        "def create_sequences(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 60  # Use the past 60 hours for prediction\n",
        "X, y = create_sequences(scaled_data, time_step)\n",
        "\n",
        "# Split data into train and test sets (80% training, 20% testing)\n",
        "split_ratio = 0.8\n",
        "split = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Reshape data for LSTM input\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('LSTMHCLTech.keras')  # This saves the model in the current directory\n",
        "print(\"Model saved successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ODw_Wgz-9qcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "dMOnf_dPu03g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('LSTMHCLTech.keras')\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "3_tZrVjAvCsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the file exists\n",
        "model_path = 'LSTMNifty.keras'\n",
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path)\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(f\"Error: File not found at '{model_path}'. Please check the file path.\")\n"
      ],
      "metadata": {
        "id": "gO4zoO9EzWze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "-ZuwsYvazZg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('LSTMHCLTech.keras')\n",
        "model = load_model('LSTMHCLTech.keras')\n",
        "model"
      ],
      "metadata": {
        "id": "wNFfoewnzfmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download HCL Tech stock data (last 2 years)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Extract closing prices\n",
        "data = hcl_data[['Close']]\n",
        "\n",
        "# Step 1: Split Data Before Normalization\n",
        "split_ratio = 0.8\n",
        "split = int(len(data) * split_ratio)\n",
        "\n",
        "train_data = data.iloc[:split]  # Training data\n",
        "test_data = data.iloc[split:]   # Testing data\n",
        "\n",
        "# Step 2: Normalize only on training data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_scaled = scaler.fit_transform(train_data[['Close']])\n",
        "test_scaled = scaler.transform(test_data[['Close']])  # Transform test data\n",
        "\n",
        "# Step 3: Prepare sequences using test data\n",
        "def create_sequences(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 60  # Using past 60 hours for prediction\n",
        "X_testH, y_testH = create_sequences(test_scaled, time_step)\n",
        "\n",
        "# Reshape for LSTM input\n",
        "X_testH = X_testH.reshape((X_testH.shape[0], X_testH.shape[1], 1))\n",
        "\n",
        "# Load pre-trained model\n",
        "model = load_model('LSTMNifty.keras')  # Load the trained model\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_hcl = model.predict(X_testH)\n",
        "y_pred_hcl = scaler.inverse_transform(y_pred_hcl.reshape(-1, 1))  # Inverse transform to original scale\n",
        "y_test_actual = scaler.inverse_transform(y_testH.reshape(-1, 1))  # Actual stock prices\n",
        "\n",
        "# Define accuracy metric (Mean Absolute Percentage Error - MAPE)\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    nonzero_idx = y_true != 0  # Avoid division by zero\n",
        "    return np.mean(np.abs((y_true[nonzero_idx] - y_pred[nonzero_idx]) / y_true[nonzero_idx])) * 100\n",
        "\n",
        "# Calculate accuracy using MAPE\n",
        "accuracy = 100 - mape(y_test_actual, y_pred_hcl)\n",
        "print(f\"Final Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data.index[time_step+1:], y_test_actual, label='Actual Price', color='blue')\n",
        "plt.plot(test_data.index[time_step+1:], y_pred_hcl, label='Predicted Price', color='red')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('HCL Tech Stock Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.title('HCL Tech Stock Price Prediction using Pre-trained LSTM')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X5bmjXK7zpig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enqgkvEyP0N2"
      },
      "source": [
        "##Nifty 50 vs HCL Tech (Original Price Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zqeYIQ8P0N3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Download NIFTY 50 and HCL Tech stock data (last 2 years)\n",
        "nifty_data = yf.download('^NSEI', period='730d', interval='1h', auto_adjust=True)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Ensure both datasets have the same timeframe\n",
        "common_dates = nifty_data.index.intersection(hcl_data.index)\n",
        "nifty_common = nifty_data.loc[common_dates]['Close']\n",
        "hcl_common = hcl_data.loc[common_dates]['Close']\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot NIFTY 50 on primary y-axis\n",
        "ax1.plot(common_dates, nifty_common, label='NIFTY 50 Index', color='blue')\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('NIFTY 50 Index Value', color='blue')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "ax1.grid()\n",
        "\n",
        "# Create secondary y-axis for HCL Tech stock\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(common_dates, hcl_common, label='HCL Tech Stock Price', color='red')\n",
        "ax2.set_ylabel('HCL Tech Stock Price (INR)', color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# Set title and format x-axis\n",
        "plt.title('Comparison of NIFTY 50 and HCL Tech Stock Prices Over Time')\n",
        "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=3))  # Set major ticks every 3 months\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))  # Format date as Year-Month\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKGh8MTUP0N3"
      },
      "source": [
        "##Nifty 50 vs HCL Tech (Predicted Price Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJBFgTkxP0N3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download NIFTY 50 stock data (last 2 years)\n",
        "nifty_data = yf.download('^NSEI', period='730d', interval='1h')\n",
        "\n",
        "# Extract closing prices\n",
        "nifty_close = nifty_data[['Close']]\n",
        "\n",
        "# Step 1: Split Data Before Normalization\n",
        "split_ratio = 0.8\n",
        "split = int(len(nifty_close) * split_ratio)\n",
        "\n",
        "train_nifty = nifty_close.iloc[:split]  # Training data\n",
        "test_nifty = nifty_close.iloc[split:]   # Testing data\n",
        "\n",
        "# Step 2: Normalize only on training data\n",
        "scaler_nifty = MinMaxScaler(feature_range=(0, 1))\n",
        "train_scaled_nifty = scaler_nifty.fit_transform(train_nifty)\n",
        "test_scaled_nifty = scaler_nifty.transform(test_nifty)\n",
        "\n",
        "# Step 3: Prepare sequences for NIFTY 50\n",
        "def create_sequences(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 60\n",
        "X_testN, y_testN = create_sequences(test_scaled_nifty, time_step)\n",
        "\n",
        "# Reshape for LSTM input\n",
        "X_testN = X_testN.reshape((X_testN.shape[0], X_testN.shape[1], 1))\n",
        "\n",
        "# ✅ Load pre-trained NIFTY model\n",
        "model_nifty = load_model('LSTMNifty.keras')  # Make sure this file is in your working directory\n",
        "\n",
        "# ✅ Predict on NIFTY 50 test data\n",
        "y_pred_nifty = model_nifty.predict(X_testN)\n",
        "y_pred_nifty = scaler_nifty.inverse_transform(y_pred_nifty.reshape(-1, 1))  # Inverse transform to original scale\n",
        "y_test_actual_nifty = scaler_nifty.inverse_transform(y_testN.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Ensure both datasets have the same timeframe\n",
        "common_dates = nifty_data.index[split+time_step+1:].intersection(hcl_data.index[split+time_step+1:])\n",
        "common_indices = np.where(hcl_data.index[split+time_step+1:].isin(common_dates))[0]  # Get index positions\n",
        "\n",
        "# Extract common prediction values using indices\n",
        "y_pred_nifty_common = y_pred_nifty[common_indices]\n",
        "y_pred_hcl_common = y_pred_hcl[common_indices]\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Plot predicted NIFTY 50 on primary y-axis\n",
        "ax1.plot(common_dates, y_pred_nifty_common, label='Predicted NIFTY 50 Index', color='blue', linestyle='dashed')\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Predicted NIFTY 50 Index Value', color='blue')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "ax1.grid()\n",
        "\n",
        "# Create secondary y-axis for predicted HCL Tech stock\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(common_dates, y_pred_hcl_common, label='Predicted HCL Tech Stock Price', color='red', linestyle='dashed')\n",
        "ax2.set_ylabel('Predicted HCL Tech Stock Price (INR)', color='red')\n",
        "ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# Set title and format x-axis\n",
        "plt.title('Comparison of Predicted NIFTY 50 and Predicted HCL Tech Stock Prices Over Time')\n",
        "ax1.xaxis.set_major_locator(mdates.MonthLocator())\n",
        "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JmmOlBeS2D1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download NIFTY 50 and HCL Tech stock data (last 2 years)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "nifty_data = yf.download('^NSEI', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Merge the data on index (date)\n",
        "merged = pd.merge(nifty_data['Close'], hcl_data['Close'], left_index=True, right_index=True)\n",
        "\n",
        "# Rename columns\n",
        "merged.columns = ['Close_nifty', 'Close_hcl']\n",
        "\n",
        "# Calculate the Pearson correlation coefficient\n",
        "correlation = merged['Close_nifty'].corr(merged['Close_hcl'])\n",
        "\n",
        "print(f\"Correlation between NIFTY 50 and HCL Tech: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "id": "HE-G_cNa4XtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Download HCL Tech and NIFTY 50 stock data (last 2 years)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "nifty_data = yf.download('^NSEI', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Merge data on index\n",
        "merged = pd.merge(nifty_data['Close'], hcl_data['Close'], left_index=True, right_index=True)\n",
        "\n",
        "# Rename columns for clarity\n",
        "merged.columns = ['Close_nifty', 'Close_hcl']\n",
        "\n",
        "# Create example predicted values for NIFTY 50 and HCL Tech (you would replace these with your predictions)\n",
        "# For the sake of example, using the actual closing prices as predicted values\n",
        "y_pred_nifty = merged['Close_nifty'].values\n",
        "y_pred_hcl = merged['Close_hcl'].values\n",
        "\n",
        "# Calculate correlation using NumPy's corrcoef function\n",
        "correlation = np.corrcoef(y_pred_nifty.flatten(), y_pred_hcl.flatten())[0, 1]\n",
        "\n",
        "print(f\"Correlation between predicted Nifty50 and HCL Tech Stock prices: {correlation:.2f}\")\n"
      ],
      "metadata": {
        "id": "h8Ni1Apn_uSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example predicted values for NIFTY 50 and HCL Tech (replace these with your actual predictions)\n",
        "# For the sake of the example, we are using random data. You should replace this with actual model predictions\n",
        "y_pred_nifty_common = np.random.rand(100)  # Replace with actual Nifty predictions\n",
        "y_pred_hcl_common = np.random.rand(100)  # Replace with actual HCL predictions\n",
        "\n",
        "# Calculate the correlation (using NumPy's corrcoef function)\n",
        "correlation = np.corrcoef(y_pred_nifty_common, y_pred_hcl_common)[0, 1]\n",
        "\n",
        "# Create scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_nifty_common, y_pred_hcl_common, alpha=0.5, color='blue')  # alpha for transparency\n",
        "plt.title('Correlation between Predicted Nifty50 and HCL Tech Stock Prices')\n",
        "plt.xlabel('Predicted Nifty50 Price')\n",
        "plt.ylabel('Predicted HCL Tech Stock Price')\n",
        "\n",
        "# Add correlation coefficient to the plot\n",
        "plt.text(0.1, 0.9, f'Correlation: {correlation:.2f}', transform=plt.gca().transAxes, fontsize=12)\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lyGF4B-RAHII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##HYPERPARAMETRIC TUNING\n"
      ],
      "metadata": {
        "id": "l-KNPjIsChOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuned Model"
      ],
      "metadata": {
        "id": "Hs_TR9vpGCw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define the tuned LSTM model\n",
        "tuned_model = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(time_step, 1)),  # More units\n",
        "    Dropout(0.3),  # Increased dropout\n",
        "    LSTM(units=64, return_sequences=True),  # Another LSTM layer\n",
        "    Dropout(0.3),  # Increased dropout again\n",
        "    LSTM(units=64),  # Increased units in the last LSTM layer\n",
        "    Dropout(0.3),  # Increased dropout\n",
        "    Dense(units=32, activation='relu'),  # More neurons in Dense layer\n",
        "    Dense(units=1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and mean squared error loss\n",
        "tuned_model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Print the summary of the model\n",
        "tuned_model.summary()\n"
      ],
      "metadata": {
        "id": "TgYv5bSHDA8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Download data (HCL Tech as an example)\n",
        "hcl_data = yf.download('HCLTECH.NS', period='730d', interval='1h', auto_adjust=True)\n",
        "\n",
        "# Extract the 'Close' prices\n",
        "data = hcl_data[['Close']]\n",
        "\n",
        "# Split data into training and test sets\n",
        "split_ratio = 0.8\n",
        "split = int(len(data) * split_ratio)\n",
        "\n",
        "train_data = data.iloc[:split]\n",
        "test_data = data.iloc[split:]\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Prepare the data for LSTM (creating sequences)\n",
        "def create_sequences(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step), 0])\n",
        "        y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 60  # Using 60 time steps (past 60 hours)\n",
        "X_train, y_train = create_sequences(train_scaled, time_step)\n",
        "X_test, y_test = create_sequences(test_scaled, time_step)\n",
        "\n",
        "# Reshaping the data for LSTM input\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Define the LSTM model\n",
        "tuned_model = Sequential([\n",
        "    LSTM(units=64, return_sequences=True, input_shape=(time_step, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(units=64, return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(units=64),\n",
        "    Dropout(0.3),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "tuned_model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Define custom callback for monitoring epoch progress\n",
        "class EpochCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch+1} - Loss: {logs['loss']:.4f} - Val Loss: {logs['val_loss']:.4f}\")\n",
        "\n",
        "# Train the model and store the training history\n",
        "history = tuned_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[EpochCallback()]  # Using the custom callback\n",
        ")\n",
        "\n",
        "# You can now access the training history (loss and metrics)\n",
        "print(f\"Training History: {history.history}\")\n"
      ],
      "metadata": {
        "id": "sBMmTKxwDpEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model and store the training history\n",
        "history = tuned_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy (if available)\n",
        "if 'accuracy' in history.history:\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qzG55Ou763hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_tuned = tuned_model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions and actual values to get them back to original scale\n",
        "y_pred_tuned_actual = scaler.inverse_transform(y_pred_tuned.reshape(-1, 1))\n",
        "y_test_actual_tuned = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Calculate the MAPE for the tuned model\n",
        "accuracy = 100 - mape(y_test_actual_tuned, y_pred_tuned_actual)\n",
        "\n",
        "print(f\"Final Model Accuracy (MAPE): {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "EzO4YWTiQlWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained tuned model to a file\n",
        "tuned_model.save('LSTMTuned.keras')\n",
        "\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "WNPstzSTEyM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuned Nifty50\n"
      ],
      "metadata": {
        "id": "dKkQz0waDXE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data using the tuned model\n",
        "y_pred_nifty_tuned = tuned_model.predict(X_test)\n",
        "y_pred_nifty_tuned = scaler.inverse_transform(y_pred_nifty_tuned.reshape(-1, 1))\n",
        "y_test_actual_tuned = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Calculate accuracy using MAPE (Mean Absolute Percentage Error)\n",
        "accuracy = 100 - mape(y_test_actual_tuned, y_pred_nifty_tuned)\n",
        "print(f\"Final Model Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Plot results year-wise\n",
        "plt.figure(figsize=(12, 6))\n",
        "# Adjust the x-axis data to match the length of y_test_actual_tuned\n",
        "plt.plot(nifty_data.index[split + time_step + 1:split + time_step + 1 + len(y_test_actual_tuned)], y_test_actual_tuned, label='Actual Price')\n",
        "plt.plot(nifty_data.index[split + time_step + 1:split + time_step + 1 + len(y_pred_nifty_tuned)], y_pred_nifty_tuned, label='Predicted Price')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('NIFTY 50 Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.title('NIFTY 50 Price Prediction using LSTM-Tuned Model (Year-wise)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XuzvgE0GFECh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tuned HCL Tech"
      ],
      "metadata": {
        "id": "z14QghdgGW2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results for HCL Tech\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Ensure the x-axis length matches the predicted and actual values\n",
        "plot_dates = hcl_data.index[split + time_step + 1:split + time_step + 1 + len(y_test_actual_tuned)]\n",
        "\n",
        "plt.plot(plot_dates, y_test_actual_tuned, label='Actual Price')\n",
        "plt.plot(plot_dates, y_pred_hcl_tuned, label='Predicted Price (Tuned Model)')\n",
        "\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('HCL Tech Stock Price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.title('HCL Tech Stock Price Prediction using Tuned LSTM')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4APfIi1uGobL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvxskykeUzdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ytlWbSK9Umvu",
        "Q1xCB4ccUqfJ",
        "l1wHv0ZaW29S",
        "9TrZbignMgZi",
        "UxdmRubHPQWm",
        "iYXcc_kKURor",
        "eHQC1D-3RqcI",
        "nJcGYU6_UgVp",
        "noYhbmlwU2nh",
        "oclDbkFFP0Nk",
        "enqgkvEyP0N2",
        "KKGh8MTUP0N3",
        "Hs_TR9vpGCw-",
        "dKkQz0waDXE5",
        "z14QghdgGW2H"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}